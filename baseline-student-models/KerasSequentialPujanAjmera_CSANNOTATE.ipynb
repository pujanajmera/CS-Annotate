{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasSequentialPujanAjmera- CSANNOTATE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F5wxluwF59y6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A-KB2IQDsi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "import statistics\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5wxluwF59y6",
        "colab_type": "text"
      },
      "source": [
        "## Keras Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw6tYhjjFdJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Due to keras not having f1 score, recall, and precision built in, it must be defined. Use keras backend for shortening code\n",
        "from keras import backend as K\n",
        "\n",
        "#Define recall by the ratio of true positive to possible positives. k.epsilon is a fuzzy constant used to prevent dividing by 0\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "#Define precision as the ratio of true positives to predicted positives\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "#Define f1 score as the ratio of the product to the sum of precision and recall, scaled by 2\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SuSgPnC5ytU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url=\"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/train_features.csv\"\n",
        "s=requests.get(url).content\n",
        "training_X = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "trainX = training_X.values\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/train_target.csv\"\n",
        "s=requests.get(url).content\n",
        "training_y = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/test_features.csv\"\n",
        "s=requests.get(url).content\n",
        "testing_X = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "testX = testing_X.values\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/test_target.csv\"\n",
        "s=requests.get(url).content\n",
        "testing_y = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmPXaZQR5Ws6",
        "colab_type": "code",
        "outputId": "0538f302-ef28-416b-9b38-24bc4f599d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#%%capture\n",
        "data = pd.DataFrame(columns = ['Structural Feature', 'Average f-1 score', 'Std Dev'])\n",
        "for structural_feature in ('astack','nastack','pair','pucker_C1p_exo','pucker_C2p_endo','pucker_C2p_exo','pucker_C3p_endo','pucker_C3p_exo','pucker_C4p_exo','sasa','syn_anti'):\n",
        "  #Can put data link here:\n",
        "  training_y_2 = training_y[[structural_feature]]\n",
        "  trainy = training_y_2.values\n",
        "  testing_y_2 = testing_y[[structural_feature]]\n",
        "  testy = testing_y_2.values\n",
        "  # setup scaler\n",
        "  temp = list()\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(trainX)\n",
        "  trainX_scaled = scaler.transform(trainX)\n",
        "  testX_scaled = scaler.transform(testX)\n",
        "  for i in range(0,2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_shape = (167,), activation = 'sigmoid'))\n",
        "    model.add(Dense(100, activation = 'sigmoid'))\n",
        "    model.add(Dense(50, activation = 'sigmoid'))\n",
        "    model.add(Dense((1), activation = 'sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1_m,precision_m, recall_m])\n",
        "    model.fit(trainX_scaled, trainy, nb_epoch = 10)\n",
        "    y_true, y_pred = np.int_(testy), model.predict(testX_scaled)\n",
        "    report = classification_report(y_true, y_pred.round(), output_dict=True)\n",
        "    temp.append(report['weighted avg']['f1-score'])\n",
        "  print(structural_feature, statistics.mean(temp), statistics.stdev(temp))\n",
        "  data = data.append(pd.DataFrame([[structural_feature, statistics.mean(temp), statistics.stdev(temp)]], columns = ['Structural Feature', 'Average f-1 score', 'Std Dev']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2748/2748 [==============================] - 1s 287us/step - loss: 0.5478 - acc: 0.7540 - f1_m: 0.8322 - precision_m: 0.7515 - recall_m: 0.9539\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 51us/step - loss: 0.5009 - acc: 0.7726 - f1_m: 0.8698 - precision_m: 0.7726 - recall_m: 1.0000\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.4609 - acc: 0.7908 - f1_m: 0.8749 - precision_m: 0.8083 - recall_m: 0.9584\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 52us/step - loss: 0.4511 - acc: 0.7973 - f1_m: 0.8746 - precision_m: 0.8220 - recall_m: 0.9385\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.4463 - acc: 0.7999 - f1_m: 0.8763 - precision_m: 0.8278 - recall_m: 0.9361\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 51us/step - loss: 0.4418 - acc: 0.8100 - f1_m: 0.8832 - precision_m: 0.8304 - recall_m: 0.9482\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 51us/step - loss: 0.4370 - acc: 0.8119 - f1_m: 0.8840 - precision_m: 0.8346 - recall_m: 0.9438\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 51us/step - loss: 0.4336 - acc: 0.8173 - f1_m: 0.8867 - precision_m: 0.8380 - recall_m: 0.9466\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.4322 - acc: 0.8140 - f1_m: 0.8859 - precision_m: 0.8334 - recall_m: 0.9496\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.4278 - acc: 0.8177 - f1_m: 0.8889 - precision_m: 0.8333 - recall_m: 0.9570\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 0s 171us/step - loss: 0.5313 - acc: 0.7726 - f1_m: 0.8691 - precision_m: 0.7726 - recall_m: 1.0000\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.4874 - acc: 0.7769 - f1_m: 0.8704 - precision_m: 0.7820 - recall_m: 0.9875\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.4576 - acc: 0.7955 - f1_m: 0.8761 - precision_m: 0.8135 - recall_m: 0.9563\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.4499 - acc: 0.8053 - f1_m: 0.8806 - precision_m: 0.8262 - recall_m: 0.9474\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.4468 - acc: 0.8082 - f1_m: 0.8812 - precision_m: 0.8297 - recall_m: 0.9459\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.4399 - acc: 0.8108 - f1_m: 0.8824 - precision_m: 0.8358 - recall_m: 0.9390\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.4390 - acc: 0.8155 - f1_m: 0.8865 - precision_m: 0.8340 - recall_m: 0.9509\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.4326 - acc: 0.8126 - f1_m: 0.8845 - precision_m: 0.8342 - recall_m: 0.9451\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.4318 - acc: 0.8133 - f1_m: 0.8849 - precision_m: 0.8351 - recall_m: 0.9457\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.4304 - acc: 0.8159 - f1_m: 0.8859 - precision_m: 0.8392 - recall_m: 0.9443\n",
            "astack 0.7641398769098746 0.003974859716257084\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 187us/step - loss: 0.3803 - acc: 0.8552 - f1_m: 0.0079 - precision_m: 0.0044 - recall_m: 0.0466\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.3136 - acc: 0.8930 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.2771 - acc: 0.8930 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.2451 - acc: 0.8923 - f1_m: 0.0124 - precision_m: 0.0233 - recall_m: 0.0087\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.2323 - acc: 0.9068 - f1_m: 0.3231 - precision_m: 0.4935 - recall_m: 0.2876\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.2266 - acc: 0.9130 - f1_m: 0.4310 - precision_m: 0.6049 - recall_m: 0.3736\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 52us/step - loss: 0.2239 - acc: 0.9145 - f1_m: 0.4573 - precision_m: 0.6044 - recall_m: 0.4205\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.2205 - acc: 0.9174 - f1_m: 0.4692 - precision_m: 0.5741 - recall_m: 0.4389\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.2203 - acc: 0.9156 - f1_m: 0.4755 - precision_m: 0.6117 - recall_m: 0.4455\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.2158 - acc: 0.9199 - f1_m: 0.5086 - precision_m: 0.6426 - recall_m: 0.4770\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 231us/step - loss: 0.3836 - acc: 0.8504 - f1_m: 0.0130 - precision_m: 0.0076 - recall_m: 0.0582\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 52us/step - loss: 0.3140 - acc: 0.8930 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.2742 - acc: 0.8930 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.2414 - acc: 0.8941 - f1_m: 0.0633 - precision_m: 0.1126 - recall_m: 0.0484\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 52us/step - loss: 0.2343 - acc: 0.9021 - f1_m: 0.2982 - precision_m: 0.4348 - recall_m: 0.2615\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.2262 - acc: 0.9087 - f1_m: 0.4332 - precision_m: 0.5788 - recall_m: 0.4002\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.2252 - acc: 0.9156 - f1_m: 0.4771 - precision_m: 0.6068 - recall_m: 0.4610\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.2206 - acc: 0.9181 - f1_m: 0.4997 - precision_m: 0.6192 - recall_m: 0.4738\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.2197 - acc: 0.9210 - f1_m: 0.4870 - precision_m: 0.6179 - recall_m: 0.4641\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.2164 - acc: 0.9214 - f1_m: 0.5263 - precision_m: 0.6601 - recall_m: 0.4937\n",
            "nastack 0.8335320512639367 0.0037039546589474684\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 239us/step - loss: 0.5689 - acc: 0.7132 - f1_m: 0.7971 - precision_m: 0.7029 - recall_m: 0.9307\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.4552 - acc: 0.7817 - f1_m: 0.8712 - precision_m: 0.7823 - recall_m: 0.9889\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.3888 - acc: 0.8301 - f1_m: 0.8902 - precision_m: 0.8580 - recall_m: 0.9294\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.3749 - acc: 0.8362 - f1_m: 0.8919 - precision_m: 0.8681 - recall_m: 0.9225\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.3685 - acc: 0.8428 - f1_m: 0.8957 - precision_m: 0.8754 - recall_m: 0.9221\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.3604 - acc: 0.8428 - f1_m: 0.8967 - precision_m: 0.8739 - recall_m: 0.9252\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.3537 - acc: 0.8508 - f1_m: 0.9025 - precision_m: 0.8827 - recall_m: 0.9269\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.3468 - acc: 0.8512 - f1_m: 0.9009 - precision_m: 0.8804 - recall_m: 0.9278\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.3413 - acc: 0.8541 - f1_m: 0.9043 - precision_m: 0.8853 - recall_m: 0.9278\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3386 - acc: 0.8559 - f1_m: 0.9053 - precision_m: 0.8864 - recall_m: 0.9297\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 277us/step - loss: 0.5716 - acc: 0.7151 - f1_m: 0.7968 - precision_m: 0.6998 - recall_m: 0.9301\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.4708 - acc: 0.7686 - f1_m: 0.8640 - precision_m: 0.7682 - recall_m: 0.9948\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.3993 - acc: 0.8308 - f1_m: 0.8907 - precision_m: 0.8566 - recall_m: 0.9333\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.3809 - acc: 0.8341 - f1_m: 0.8920 - precision_m: 0.8676 - recall_m: 0.9226\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.3676 - acc: 0.8461 - f1_m: 0.8992 - precision_m: 0.8728 - recall_m: 0.9319\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3610 - acc: 0.8479 - f1_m: 0.8998 - precision_m: 0.8787 - recall_m: 0.9261\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.3552 - acc: 0.8475 - f1_m: 0.8998 - precision_m: 0.8806 - recall_m: 0.9241\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.3516 - acc: 0.8457 - f1_m: 0.8985 - precision_m: 0.8773 - recall_m: 0.9254\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3463 - acc: 0.8548 - f1_m: 0.9041 - precision_m: 0.8861 - recall_m: 0.9275\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.3398 - acc: 0.8566 - f1_m: 0.9056 - precision_m: 0.8858 - recall_m: 0.9302\n",
            "pair 0.8351383485735675 0.0013514311543191787\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 302us/step - loss: 0.2087 - acc: 0.9232 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.0933 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.0907 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.0889 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.0874 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.0863 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.0845 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.0824 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.0805 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.0783 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 311us/step - loss: 0.1615 - acc: 0.9811 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.0922 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.0900 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.0888 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.0876 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.0865 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.0849 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 54us/step - loss: 0.0832 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.0809 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.0786 - acc: 0.9814 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "pucker_C1p_exo 0.9781558608844997 0.0\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 333us/step - loss: 0.2747 - acc: 0.9108 - f1_m: 0.0034 - precision_m: 0.0018 - recall_m: 0.0349\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.2108 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.1954 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.1761 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.1653 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.1613 - acc: 0.9429 - f1_m: 0.0299 - precision_m: 0.0466 - recall_m: 0.0243\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.1589 - acc: 0.9429 - f1_m: 0.0475 - precision_m: 0.0626 - recall_m: 0.0420\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.1572 - acc: 0.9421 - f1_m: 0.0714 - precision_m: 0.0990 - recall_m: 0.0602\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1543 - acc: 0.9440 - f1_m: 0.1169 - precision_m: 0.1834 - recall_m: 0.0955\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 53us/step - loss: 0.1532 - acc: 0.9429 - f1_m: 0.1270 - precision_m: 0.1591 - recall_m: 0.1163\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 389us/step - loss: 0.2506 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.2120 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.1955 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.1745 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1629 - acc: 0.9421 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.1598 - acc: 0.9421 - f1_m: 0.0311 - precision_m: 0.0466 - recall_m: 0.0256\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1582 - acc: 0.9429 - f1_m: 0.1153 - precision_m: 0.1747 - recall_m: 0.0957\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.1555 - acc: 0.9443 - f1_m: 0.1190 - precision_m: 0.1720 - recall_m: 0.1009\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.1531 - acc: 0.9436 - f1_m: 0.1772 - precision_m: 0.2552 - recall_m: 0.1566\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1521 - acc: 0.9425 - f1_m: 0.1143 - precision_m: 0.1844 - recall_m: 0.0946\n",
            "pucker_C2p_endo 0.9600653834230477 0.0\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 398us/step - loss: 0.3281 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.3220 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3188 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3155 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3134 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3107 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.3115 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3086 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.3079 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3078 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 408us/step - loss: 0.3693 - acc: 0.8632 - f1_m: 0.0084 - precision_m: 0.0047 - recall_m: 0.0466\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.3227 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3196 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.3175 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3163 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3129 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3118 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.3103 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.3096 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.3097 - acc: 0.9003 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "pucker_C2p_exo 0.7252766658817988 0.0\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 448us/step - loss: 0.6294 - acc: 0.6718 - f1_m: 0.8000 - precision_m: 0.6718 - recall_m: 1.0000\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.6007 - acc: 0.6878 - f1_m: 0.8063 - precision_m: 0.6882 - recall_m: 0.9855\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.5675 - acc: 0.7198 - f1_m: 0.8110 - precision_m: 0.7330 - recall_m: 0.9161\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.5588 - acc: 0.7260 - f1_m: 0.8145 - precision_m: 0.7416 - recall_m: 0.9101\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.5564 - acc: 0.7274 - f1_m: 0.8155 - precision_m: 0.7439 - recall_m: 0.9117\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.5496 - acc: 0.7296 - f1_m: 0.8158 - precision_m: 0.7471 - recall_m: 0.9068\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.5485 - acc: 0.7300 - f1_m: 0.8161 - precision_m: 0.7442 - recall_m: 0.9107\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.5440 - acc: 0.7351 - f1_m: 0.8184 - precision_m: 0.7466 - recall_m: 0.9138\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.5418 - acc: 0.7362 - f1_m: 0.8209 - precision_m: 0.7473 - recall_m: 0.9175\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.5397 - acc: 0.7449 - f1_m: 0.8257 - precision_m: 0.7574 - recall_m: 0.9155\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 499us/step - loss: 0.6299 - acc: 0.6659 - f1_m: 0.7915 - precision_m: 0.6630 - recall_m: 0.9884\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.5894 - acc: 0.6921 - f1_m: 0.8037 - precision_m: 0.6969 - recall_m: 0.9611\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.5616 - acc: 0.7238 - f1_m: 0.8132 - precision_m: 0.7354 - recall_m: 0.9174\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.5592 - acc: 0.7263 - f1_m: 0.8170 - precision_m: 0.7399 - recall_m: 0.9230\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.5545 - acc: 0.7307 - f1_m: 0.8157 - precision_m: 0.7462 - recall_m: 0.9082\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 58us/step - loss: 0.5515 - acc: 0.7296 - f1_m: 0.8172 - precision_m: 0.7427 - recall_m: 0.9168\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 55us/step - loss: 0.5473 - acc: 0.7293 - f1_m: 0.8167 - precision_m: 0.7438 - recall_m: 0.9150\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.5412 - acc: 0.7347 - f1_m: 0.8172 - precision_m: 0.7485 - recall_m: 0.9086\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.5393 - acc: 0.7413 - f1_m: 0.8251 - precision_m: 0.7532 - recall_m: 0.9191\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 57us/step - loss: 0.5368 - acc: 0.7420 - f1_m: 0.8246 - precision_m: 0.7507 - recall_m: 0.9240\n",
            "pucker_C3p_endo 0.7260122150792383 0.004374024530480016\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 525us/step - loss: 0.1832 - acc: 0.9440 - f1_m: 7.2780e-04 - precision_m: 3.7564e-04 - recall_m: 0.0116\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1039 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.1006 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0974 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.0933 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0892 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0833 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0777 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0737 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0703 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 1s 525us/step - loss: 0.2224 - acc: 0.9196 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.1060 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.1025 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 56us/step - loss: 0.1001 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0977 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0948 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0913 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0860 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0806 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0749 - acc: 0.9778 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "pucker_C3p_exo 0.9672744902631509 0.0\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 576us/step - loss: 0.3913 - acc: 0.8424 - f1_m: 0.0112 - precision_m: 0.0062 - recall_m: 0.0699\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3254 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.3245 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3239 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 66us/step - loss: 0.3227 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.3215 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.3198 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 66us/step - loss: 0.3196 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 69us/step - loss: 0.3184 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3133 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 617us/step - loss: 0.3354 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3264 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3241 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 69us/step - loss: 0.3232 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3200 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3221 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.3185 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 67us/step - loss: 0.3146 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.3150 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 66us/step - loss: 0.3113 - acc: 0.8999 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "pucker_C4p_exo 0.9455946598648685 0.0\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 634us/step - loss: 0.4852 - acc: 0.8133 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 66us/step - loss: 0.4292 - acc: 0.8246 - f1_m: 0.0911 - precision_m: 0.2387 - recall_m: 0.0582\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3934 - acc: 0.8432 - f1_m: 0.3520 - precision_m: 0.6568 - recall_m: 0.2569\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3819 - acc: 0.8475 - f1_m: 0.3935 - precision_m: 0.6593 - recall_m: 0.3061\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3773 - acc: 0.8512 - f1_m: 0.3987 - precision_m: 0.7166 - recall_m: 0.3091\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.3695 - acc: 0.8563 - f1_m: 0.4382 - precision_m: 0.6863 - recall_m: 0.3392\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 60us/step - loss: 0.3658 - acc: 0.8552 - f1_m: 0.4187 - precision_m: 0.6637 - recall_m: 0.3299\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3615 - acc: 0.8544 - f1_m: 0.4318 - precision_m: 0.7393 - recall_m: 0.3340\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 59us/step - loss: 0.3617 - acc: 0.8530 - f1_m: 0.4298 - precision_m: 0.6995 - recall_m: 0.3517\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.3541 - acc: 0.8541 - f1_m: 0.4170 - precision_m: 0.6910 - recall_m: 0.3229\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 694us/step - loss: 0.4759 - acc: 0.8137 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.4211 - acc: 0.8293 - f1_m: 0.1412 - precision_m: 0.3408 - recall_m: 0.0938\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.3915 - acc: 0.8461 - f1_m: 0.3485 - precision_m: 0.6030 - recall_m: 0.2687\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.3836 - acc: 0.8479 - f1_m: 0.3846 - precision_m: 0.6616 - recall_m: 0.2956\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.3768 - acc: 0.8512 - f1_m: 0.4068 - precision_m: 0.6915 - recall_m: 0.3163\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.3727 - acc: 0.8508 - f1_m: 0.4115 - precision_m: 0.6704 - recall_m: 0.3221\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.3683 - acc: 0.8519 - f1_m: 0.4173 - precision_m: 0.7075 - recall_m: 0.3281\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 67us/step - loss: 0.3608 - acc: 0.8548 - f1_m: 0.4317 - precision_m: 0.6757 - recall_m: 0.3422\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.3603 - acc: 0.8570 - f1_m: 0.4327 - precision_m: 0.7191 - recall_m: 0.3417\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.3613 - acc: 0.8544 - f1_m: 0.4176 - precision_m: 0.6711 - recall_m: 0.3390\n",
            "sasa 0.938083525557978 0.0018707223735932542\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 709us/step - loss: 0.1472 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.1028 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0980 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0912 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0829 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0740 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0678 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0629 - acc: 0.9796 - f1_m: 0.0679 - precision_m: 0.0815 - recall_m: 0.0621\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0588 - acc: 0.9829 - f1_m: 0.1762 - precision_m: 0.1921 - recall_m: 0.1727\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 62us/step - loss: 0.0568 - acc: 0.9833 - f1_m: 0.2011 - precision_m: 0.2431 - recall_m: 0.1858\n",
            "Epoch 1/10\n",
            "2748/2748 [==============================] - 2s 768us/step - loss: 0.1366 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2748/2748 [==============================] - 0s 66us/step - loss: 0.1035 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0985 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2748/2748 [==============================] - 0s 69us/step - loss: 0.0922 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2748/2748 [==============================] - 0s 61us/step - loss: 0.0840 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2748/2748 [==============================] - 0s 64us/step - loss: 0.0752 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.0674 - acc: 0.9774 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.0629 - acc: 0.9789 - f1_m: 0.0451 - precision_m: 0.0451 - recall_m: 0.0451\n",
            "Epoch 9/10\n",
            "2748/2748 [==============================] - 0s 63us/step - loss: 0.0583 - acc: 0.9847 - f1_m: 0.2018 - precision_m: 0.2445 - recall_m: 0.1824\n",
            "Epoch 10/10\n",
            "2748/2748 [==============================] - 0s 65us/step - loss: 0.0551 - acc: 0.9840 - f1_m: 0.2356 - precision_m: 0.2678 - recall_m: 0.2222\n",
            "syn_anti 0.9919843703362007 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDb-oT0cATQm",
        "colab_type": "code",
        "outputId": "d5dea1aa-bcdc-47d5-b42f-7c9454a193b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Structural Feature</th>\n",
              "      <th>Average f-1 score</th>\n",
              "      <th>Std Dev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>astack</td>\n",
              "      <td>0.764140</td>\n",
              "      <td>0.003975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nastack</td>\n",
              "      <td>0.833532</td>\n",
              "      <td>0.003704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pair</td>\n",
              "      <td>0.835138</td>\n",
              "      <td>0.001351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C1p_exo</td>\n",
              "      <td>0.978156</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C2p_endo</td>\n",
              "      <td>0.960065</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C2p_exo</td>\n",
              "      <td>0.725277</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C3p_endo</td>\n",
              "      <td>0.726012</td>\n",
              "      <td>0.004374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C3p_exo</td>\n",
              "      <td>0.967274</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pucker_C4p_exo</td>\n",
              "      <td>0.945595</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sasa</td>\n",
              "      <td>0.938084</td>\n",
              "      <td>0.001871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>syn_anti</td>\n",
              "      <td>0.991984</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Structural Feature  Average f-1 score   Std Dev\n",
              "0             astack           0.764140  0.003975\n",
              "0            nastack           0.833532  0.003704\n",
              "0               pair           0.835138  0.001351\n",
              "0     pucker_C1p_exo           0.978156  0.000000\n",
              "0    pucker_C2p_endo           0.960065  0.000000\n",
              "0     pucker_C2p_exo           0.725277  0.000000\n",
              "0    pucker_C3p_endo           0.726012  0.004374\n",
              "0     pucker_C3p_exo           0.967274  0.000000\n",
              "0     pucker_C4p_exo           0.945595  0.000000\n",
              "0               sasa           0.938084  0.001871\n",
              "0           syn_anti           0.991984  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}