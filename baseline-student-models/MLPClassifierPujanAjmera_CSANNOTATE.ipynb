{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPClassifierPujanAjmera- CSANNOTATE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QXCOApUt6CY2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A-KB2IQDsi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "import statistics\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCOApUt6CY2",
        "colab_type": "text"
      },
      "source": [
        "## Keras MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Du2XW3D73z",
        "colab_type": "code",
        "outputId": "90176287-0af1-4561-8e2a-e6467bcf3fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "for structural_feature in ('astack','nastack','pair','pucker_C1p_exo','pucker_C2p_endo','pucker_C2p_exo','pucker_C3p_endo','pucker_C3p_exo','pucker_C4p_exo','sasa','syn_anti'):\n",
        "  #Can put data link here:\n",
        "  url=\"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/train_features.csv\"\n",
        "  s=requests.get(url).content\n",
        "  training_X = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "  '''for num in range(133,167):\n",
        "    training_X = training_X.drop(columns = [f'{num}'])'''\n",
        "  trainX = training_X.values\n",
        "\n",
        "  url = \"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/train_target.csv\"\n",
        "  s=requests.get(url).content\n",
        "  training_y = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "  training_y = training_y[[structural_feature]]\n",
        "  trainy = training_y.values\n",
        "\n",
        "  url=\"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/test_features.csv\"\n",
        "  s=requests.get(url).content\n",
        "  testing_X = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "  '''for num in range(133,167):\n",
        "    testing_X = testing_X.drop(columns = [f'{num}'])'''\n",
        "  testX = testing_X.values\n",
        "\n",
        "  url = \"https://raw.githubusercontent.com/atfrank/CS-Annotate/master/data/test_target.csv\"\n",
        "  s=requests.get(url).content\n",
        "  testing_y = pd.read_csv(io.StringIO(s.decode('utf-8')), sep = ' ')\n",
        "  testing_y = testing_y[[structural_feature]]\n",
        "  testy = testing_y.values\n",
        "  # setup scaler\n",
        "  temp = list()\n",
        "  for i in range(0,20):\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(trainX)\n",
        "\n",
        "    # transform input\n",
        "    trainX_scaled = scaler.transform(trainX)\n",
        "    testX_scaled = scaler.transform(testX)\n",
        "\n",
        "    clf = MLPClassifier(hidden_layer_sizes=(50,100,50), max_iter=100, activation = 'logistic', solver = 'lbfgs')\n",
        "    clf.fit(trainX_scaled, np.int_(trainy))\n",
        "    y_true, y_pred = np.int_(testy) , clf.predict(testX_scaled)\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    temp.append(report['weighted avg']['f1-score'])\n",
        "\n",
        "  print(structural_feature, statistics.mean(temp), statistics.stdev(temp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "astack 0.7493714372048298 0.03050616917983856\n",
            "nastack 0.8290858984335309 0.017806763286027018\n",
            "pair 0.8063249345968557 0.04688614601285803\n",
            "pucker_C1p_exo 0.9781558608844997 0.0\n",
            "pucker_C2p_endo 0.92290000823703 0.02037044088449803\n",
            "pucker_C2p_exo 0.7269147763342094 0.011539961998864331\n",
            "pucker_C3p_endo 0.6964944348508636 0.02479711190631967\n",
            "pucker_C3p_exo 0.9672744902631509 0.0\n",
            "pucker_C4p_exo 0.9455946598648685 0.0\n",
            "sasa 0.8773960890871432 0.023872476086476784\n",
            "syn_anti 0.9707130300989747 0.008507778748535795\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}